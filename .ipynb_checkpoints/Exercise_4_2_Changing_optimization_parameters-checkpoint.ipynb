{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApEGsGnec6BZ"
   },
   "source": [
    "## Exercise 4.2 Changing optimization parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEOOH6NdV42q"
   },
   "source": [
    "In this exercise, you will use the same titanic dataset from the previous exercises. You can download the dataset from the following link:\n",
    "\n",
    "[titanic_all_numeric.csv](https://drive.google.com/file/d/11nuYS-l3EXCsGJt81y4YTt3oTnFGaB68/view?usp=drive_link)\n",
    "\n",
    "The data is pre-loaded into a pandas DataFrame called `df`. The `predictors` and `target` values are also pre-defined.\n",
    "\n",
    "You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function `get_new_model()` that creates an unoptimized model to optimize.\n",
    "\n",
    "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AWPd5Wqft_d"
   },
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNotC4abWBqN"
   },
   "source": [
    "* Import `SGD` from `tensorflow.keras.optimizers`.\n",
    "* Create a list of learning rates to try optimizing with called `lr_to_test`. The learning rates in it should be `0.000001`, `0.01`, and `1.0`.\n",
    "* Using a `for` loop to iterate over `lr_to_test`:\n",
    "  * Use the `get_new_model()` function to build a new, unoptimized model.\n",
    "  * Create an optimizer called `my_optimizer` using the `SGD()` constructor with keyword argument `learning_rate=lr`.\n",
    "  * Compile your model. Set the optimizer parameter to be the SGD object you created above, and because this is a classification problem, use `'categorical_crossentropy'` for the loss parameter, , and `metrics=['accuracy']` to see the accuracy at the end of each epoch.\n",
    "  * Fit the model using the `predictors` and the `target`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKx-pAyrlVGO"
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2uQ5t2BRtpg"
   },
   "source": [
    "Load data and convert the data to NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "dlu9wWcWcy44",
    "outputId": "cae4eb4d-d350-4206-cc8c-f2baad6c6c19"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load csv file into the dataframe: df\u001b[39;00m\n\u001b[32m      6\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mtitanic_all_numeric.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load csv file into the dataframe: df\n",
    "df = pd.read_csv(\"titanic_all_numeric.csv\")\n",
    "\n",
    "# Convert the boolean values of the 'age_was_missing' column to integer\n",
    "df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n",
    "\n",
    "# Create predictors NumPy array: predictors\n",
    "predictors = df.drop(['survived'], axis=1).values\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df['survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jf6A0pPsATU"
   },
   "source": [
    "Create a neural network for a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkgdNpMmsKmt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def get_new_model():\n",
    "  # Set up the model\n",
    "  model = Sequential()\n",
    "  model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "  model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u986qJ_NOK1h"
   },
   "source": [
    "Optimize the model with different learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdrPE2NrOjS5",
    "outputId": "870a79be-9546-4915-ad12-c1d08d705419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6483 - loss: 1.4724   \n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5725 - loss: 3.8664   \n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5573 - loss: 313.6031 \n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "_____\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = _____\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "\n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = _____\n",
    "\n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = _____\n",
    "\n",
    "    # Compile the model\n",
    "    _____\n",
    "\n",
    "    # Fit the model\n",
    "    _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecubSk7GZKKp"
   },
   "source": [
    "The ouput should be:\n",
    "\n",
    "Testing model with learning rate: 0.000001\n",
    "\n",
    "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.4074 - loss: 5.5751   \n",
    "\n",
    "\n",
    "Testing model with learning rate: 0.010000\n",
    "\n",
    "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5747 - loss: 3.3378   \n",
    "\n",
    "\n",
    "Testing model with learning rate: 1.000000\n",
    "\n",
    "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5404 - loss: 28697.6289\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (lab-ain-01)",
   "language": "python",
   "name": "lab-ain-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
