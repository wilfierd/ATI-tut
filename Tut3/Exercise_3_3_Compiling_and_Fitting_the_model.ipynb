{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilfierd/ATI-tut/blob/main/Exercise_3_3_Compiling_and_Fitting_the_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3.3 Compiling and Fitting the model\n"
      ],
      "metadata": {
        "id": "ApEGsGnec6BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you will write code to compile and fit your model.\n",
        "\n",
        "As the same as the previous exercise, you will work with a .csv file that contains some data about workers in a company. You can download this file from the following link:\n",
        "\n",
        "[hourly_wages.csv](https://drive.google.com/file/d/1elGBb48CX728knwJzU3ImHNvtuRoG7vu/view?usp=drive_link)\n",
        "\n",
        "The data is pre-loaded into a pandas DataFrame called `df`. The target variable you'll be predicting is `wage_per_hour`. For convenience, everything in `df` except for the target has been converted to a NumPy array called `predictors`. The target, `wage_per_hour`, is available as a NumPy array called `target`.\n",
        "\n",
        "You'll create a neural network with two hidden layers and an output layer. The network can be created with the `Sequential` model constructor and the `Dense` layer constructor.\n",
        "\n",
        "To compile the model, you need to specify the optimizer and loss function to use. In general, Adam optimizer is an excellent choice so you'll use the Adam optimizer and the mean squared error loss function.\n",
        "\n",
        "After successfully compiling the model, you can fit your model using the `predictors` data and the `target` data."
      ],
      "metadata": {
        "id": "mEOOH6NdV42q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions"
      ],
      "metadata": {
        "id": "-AWPd5Wqft_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Create you model with the same code in the previous exercise\n",
        "* Compile the model using `model.compile()`. Your optimizer should be `'adam'` and the loss should be `'mean_squared_error'`.\n",
        "* Fit the model using `model.fit()`. Remember that the first argument is the predictive features (`predictors`), and the data to be predicted (`target`) is the second argument."
      ],
      "metadata": {
        "id": "fNotC4abWBqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "oKx-pAyrlVGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data and convert the data to NumPy array:"
      ],
      "metadata": {
        "id": "K2uQ5t2BRtpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dlu9wWcWcy44"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Load csv file into the dataframe: df\n",
        "df = pd.read_csv(\"hourly_wages.csv\")\n",
        "# Split the dataframe df into two dataframes:\n",
        "wagePerHourDf = df.iloc[:,0]\n",
        "predictorsDf = df.iloc[:,1:df.shape[1]]\n",
        "\n",
        "# Create predictors NumPy array: predictors\n",
        "predictors = predictorsDf.to_numpy()\n",
        "\n",
        "# Create target NumPy array: target\n",
        "target = wagePerHourDf.to_numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the neural network, then compile and fit the model"
      ],
      "metadata": {
        "id": "u986qJ_NOK1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "# Set up the model: model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first layer\n",
        "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
        "\n",
        "# Add the second layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors, target)"
      ],
      "metadata": {
        "id": "rdrPE2NrOjS5",
        "outputId": "f6b32c3b-18d9-4ff6-a3e0-07e07c501b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 64.7454 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7abeef3bf950>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ouput should be similar to the following:\n",
        "\n",
        "\n",
        "17/17 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - loss: 24.1951   \n",
        "<keras.src.callbacks.history.History at 0x7f06186959f0>\n",
        "\n",
        "\n",
        "You don't have to care much about the meaning of the output. The detail will be explained soon. At this time, just think of it as a log showing model performance on the training data as we update model weights.\n"
      ],
      "metadata": {
        "id": "ecubSk7GZKKp"
      }
    }
  ]
}