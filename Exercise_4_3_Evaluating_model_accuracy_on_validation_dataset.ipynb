{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4.3 Evaluating model accuracy on validation dataset"
      ],
      "metadata": {
        "id": "ApEGsGnec6BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you will use the same titanic dataset from the previous exercises. You can download the dataset from the following link:\n",
        "\n",
        "[titanic_all_numeric.csv](https://drive.google.com/file/d/11nuYS-l3EXCsGJt81y4YTt3oTnFGaB68/view?usp=drive_link)\n",
        "\n",
        "The data is pre-loaded into a pandas DataFrame called `df`. The `predictors` and `target` values are also pre-defined.\n",
        "\n",
        "Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as `model`.\n",
        "\n",
        "Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch."
      ],
      "metadata": {
        "id": "mEOOH6NdV42q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions"
      ],
      "metadata": {
        "id": "-AWPd5Wqft_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Compile your model using `'adam'` as the optimizer and `'categorical_crossentropy'` for the loss. To see what fraction of predictions are correct (the accuracy) in each epoch, specify the additional keyword argument `metrics=['accuracy']` in `model.compile()`.\n",
        "* Fit the model using the predictors and target. Create a validation split of `30%` (or `0.3`). This will be reported in each epoch."
      ],
      "metadata": {
        "id": "fNotC4abWBqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "oKx-pAyrlVGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data and convert the data to NumPy array:"
      ],
      "metadata": {
        "id": "K2uQ5t2BRtpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlu9wWcWcy44"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load csv file into the dataframe: df\n",
        "df = pd.read_csv(\"titanic_all_numeric.csv\")\n",
        "\n",
        "# Convert the boolean values of the 'age_was_missing' column to integer\n",
        "df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n",
        "\n",
        "# Create predictors NumPy array: predictors\n",
        "predictors = df.drop(['survived'], axis=1).values\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "# Convert the target to categorical: target\n",
        "target = to_categorical(df['survived'])\n",
        "\n",
        "# Define the input shape: input_shape\n",
        "input_shape = (n_cols,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a neural network for a classification task"
      ],
      "metadata": {
        "id": "9jf6A0pPsATU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def get_new_model(input_shape):\n",
        "  # Set up the model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "wkgdNpMmsKmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and fit the model with a validation dataset:"
      ],
      "metadata": {
        "id": "u986qJ_NOK1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the model\n",
        "model = get_new_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "____\n",
        "\n",
        "# Fit the model\n",
        "hist = ____\n"
      ],
      "metadata": {
        "id": "rdrPE2NrOjS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ouput should be:\n",
        "\n",
        "20/20 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.5932 - loss: 1.0253 - val_accuracy: 0.6567 - val_loss: 0.8172\n"
      ],
      "metadata": {
        "id": "ecubSk7GZKKp"
      }
    }
  ]
}